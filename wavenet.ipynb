{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0282, -0.0244, -0.0236,  ...,  0.0104,  0.0114,  0.0126]]), 3)\n",
      "(tensor([[ 9.1553e-05, -2.7466e-04, -9.1553e-04,  ..., -3.9673e-04,\n",
      "         -4.8828e-04, -4.5776e-04]]), 2)\n",
      "(tensor([[-0.0032, -0.0017, -0.0019,  ...,  0.0024,  0.0081,  0.0065]]), 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, set_number):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the audio files.\n",
    "            set_number (int): Set number to filter the samples.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.set_number = set_number\n",
    "        self.filtered_indices = self.filter()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def filter(self):\n",
    "        filtered_indices = []\n",
    "        for idx in range(len(self.data)):\n",
    "            set_value = int(self.data.iloc[idx, 1])\n",
    "            if set_value == self.set_number:\n",
    "                filtered_indices.append(idx)\n",
    "        return filtered_indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.filtered_indices[idx]\n",
    "        file = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        class_label = int(self.data.iloc[idx, 2])\n",
    "        waveform, _ = torchaudio.load(file)\n",
    "        return waveform, class_label\n",
    "\n",
    "csv_file = 'dataset.csv'\n",
    "root_dir = 'Inregistrari'\n",
    "train_dataset = My_Dataset(csv_file, root_dir, 0)\n",
    "test_dataset = My_Dataset(csv_file, root_dir, 1)\n",
    "valid_dataset = My_Dataset(csv_file, root_dir, 2)\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n",
    "print(valid_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 16000]) torch.Size([64])\n",
      "torch.Size([64, 1, 16000]) torch.Size([64])\n",
      "torch.Size([64, 1, 16000]) torch.Size([64])\n",
      "torch.Size([64, 1, 16000]) torch.Size([64])\n",
      "Class distribution in training set: class\n",
      "4    60\n",
      "0    60\n",
      "2    59\n",
      "5    57\n",
      "3    55\n",
      "1    45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_loader):\n",
    "    print(X.shape, y.shape)\n",
    "    if batch == 3:\n",
    "        break\n",
    "\n",
    "# Print class distribution\n",
    "class_counts = train_dataset.data.iloc[train_dataset.filtered_indices, 2].value_counts()\n",
    "print(\"Class distribution in training set:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['start', 'stop', 'home', 'pick_up', 'approach', 'free']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplifiedWaveNet(\n",
      "  (init_conv): Conv1d(128, 16, kernel_size=(1,), stride=(1,))\n",
      "  (dilated_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv1d(16, 6, kernel_size=(1,), stride=(1,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SimplifiedWaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels=128, num_layers=3, num_filters=16, dilation_rates=None):\n",
    "        super(SimplifiedWaveNet, self).__init__()\n",
    "        \n",
    "        if dilation_rates is None:\n",
    "            dilation_rates = [2**i for i in range(num_layers)]\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_filters = num_filters\n",
    "        self.dilation_rates = dilation_rates\n",
    "        \n",
    "        self.init_conv = nn.Conv1d(num_channels, num_filters, kernel_size=1)\n",
    "        \n",
    "        self.dilated_layers = nn.ModuleList()\n",
    "        for dilation_rate in dilation_rates:\n",
    "            self.dilated_layers.append(nn.Sequential(\n",
    "                nn.Conv1d(num_filters, num_filters, kernel_size=2, stride=1,\n",
    "                          dilation=dilation_rate, padding=dilation_rate),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        \n",
    "        self.final_conv = nn.Conv1d(num_filters, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        \n",
    "        skip_connections = []\n",
    "        for layer in self.dilated_layers:\n",
    "            x = layer(x)\n",
    "            skip_connections.append(x)\n",
    "        \n",
    "        min_size = min([s.size(2) for s in skip_connections])\n",
    "        adjusted_skip_connections = [s[:, :, :min_size] for s in skip_connections]\n",
    "        \n",
    "        x = sum(adjusted_skip_connections)\n",
    "        x = F.relu(x)\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_simplified_wavenet(num_classes, num_channels=128, num_layers=3, num_filters=16, dilation_rates=None, device='cpu'):\n",
    "    model = SimplifiedWaveNet(num_classes, num_channels, num_layers, num_filters, dilation_rates)\n",
    "    return model.to(device)\n",
    "\n",
    "# Example usage with the correct number of input channels:\n",
    "num_input_channels = 128  # Adjust as needed\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = get_simplified_wavenet(num_classes=6, num_channels=num_input_channels, num_layers=3, num_filters=16, device=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.optim as optim\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Reduced learning rate\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, scheduler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data = data.squeeze(1)  # Remove channel dimension\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Testing function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # data = data.squeeze(1)  # Remove channel dimension\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)  # Accumulate the loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader.dataset)  # Calculate average loss\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_accuracies.append(accuracy)\n",
    "    print(f'\\nTest set: Average loss: {avg_test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 128, 1], expected input[1, 64, 16000] to have 128 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mn_epoch) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m         test(model, device, test_loader)\n\u001b[0;32m     18\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavenet_command.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, log_interval, scheduler)\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Remove channel dimension\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 32\u001b[0m, in \u001b[0;36mSimplifiedWaveNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     skip_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilated_layers:\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Antonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 128, 1], expected input[1, 64, 16000] to have 128 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming model, device, train_loader, test_loader, optimizer are defined\n",
    "# Assuming train and test functions are defined\n",
    "\n",
    "n_epoch = 150\n",
    "log_interval = 20\n",
    "\n",
    "# Example of setting up a scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval, scheduler)\n",
    "        test(model, device, test_loader)\n",
    "        torch.save(model.state_dict(), 'wavenet_command.pt')\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,033,542 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/336 (0%)]\tLoss: 1.795812\n",
      "Train Epoch: 1\tAverage Loss: 1.813363\tAccuracy: 14.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:03<09:51,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8005, Accuracy: 12/96 (12%)\n",
      "\n",
      "Train Epoch: 2 [0/336 (0%)]\tLoss: 1.776709\n",
      "Train Epoch: 2\tAverage Loss: 1.783729\tAccuracy: 17.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:07<09:29,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7961, Accuracy: 20/96 (21%)\n",
      "\n",
      "Train Epoch: 3 [0/336 (0%)]\tLoss: 1.742825\n",
      "Train Epoch: 3\tAverage Loss: 1.741670\tAccuracy: 30.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:11<09:20,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7207, Accuracy: 32/96 (33%)\n",
      "\n",
      "Train Epoch: 4 [0/336 (0%)]\tLoss: 1.694700\n",
      "Train Epoch: 4\tAverage Loss: 1.628575\tAccuracy: 36.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:15<09:19,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8101, Accuracy: 23/96 (24%)\n",
      "\n",
      "Train Epoch: 5 [0/336 (0%)]\tLoss: 1.622796\n",
      "Train Epoch: 5\tAverage Loss: 1.472799\tAccuracy: 45.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:19<09:15,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4015, Accuracy: 45/96 (47%)\n",
      "\n",
      "Train Epoch: 6 [0/336 (0%)]\tLoss: 1.202370\n",
      "Train Epoch: 6\tAverage Loss: 1.172192\tAccuracy: 55.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:22<09:08,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.2455, Accuracy: 49/96 (51%)\n",
      "\n",
      "Train Epoch: 7 [0/336 (0%)]\tLoss: 1.015187\n",
      "Train Epoch: 7\tAverage Loss: 0.887905\tAccuracy: 72.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:26<09:04,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3000, Accuracy: 47/96 (49%)\n",
      "\n",
      "Train Epoch: 8 [0/336 (0%)]\tLoss: 0.780526\n",
      "Train Epoch: 8\tAverage Loss: 0.732422\tAccuracy: 74.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:30<08:58,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0804, Accuracy: 57/96 (59%)\n",
      "\n",
      "Train Epoch: 9 [0/336 (0%)]\tLoss: 0.588676\n",
      "Train Epoch: 9\tAverage Loss: 0.542485\tAccuracy: 79.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/150 [00:34<08:58,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1875, Accuracy: 56/96 (58%)\n",
      "\n",
      "Train Epoch: 10 [0/336 (0%)]\tLoss: 0.541437\n",
      "Train Epoch: 10\tAverage Loss: 0.431883\tAccuracy: 82.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:38<08:54,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7329, Accuracy: 70/96 (73%)\n",
      "\n",
      "Train Epoch: 11 [0/336 (0%)]\tLoss: 0.287528\n",
      "Train Epoch: 11\tAverage Loss: 0.357254\tAccuracy: 86.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:42<09:00,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7642, Accuracy: 74/96 (77%)\n",
      "\n",
      "Train Epoch: 12 [0/336 (0%)]\tLoss: 0.346369\n",
      "Train Epoch: 12\tAverage Loss: 0.284541\tAccuracy: 91.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12/150 [00:46<09:02,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7254, Accuracy: 73/96 (76%)\n",
      "\n",
      "Train Epoch: 13 [0/336 (0%)]\tLoss: 0.269358\n",
      "Train Epoch: 13\tAverage Loss: 0.254212\tAccuracy: 92.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 13/150 [00:51<09:31,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7316, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/336 (0%)]\tLoss: 0.173580\n",
      "Train Epoch: 14\tAverage Loss: 0.200192\tAccuracy: 93.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/150 [00:55<09:46,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8200, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/336 (0%)]\tLoss: 0.264366\n",
      "Train Epoch: 15\tAverage Loss: 0.187320\tAccuracy: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 15/150 [00:59<09:39,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7406, Accuracy: 73/96 (76%)\n",
      "\n",
      "Train Epoch: 16 [0/336 (0%)]\tLoss: 0.191603\n",
      "Train Epoch: 16\tAverage Loss: 0.147002\tAccuracy: 95.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 16/150 [01:03<09:25,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7723, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 17 [0/336 (0%)]\tLoss: 0.135908\n",
      "Train Epoch: 17\tAverage Loss: 0.135252\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 17/150 [01:08<09:18,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7387, Accuracy: 77/96 (80%)\n",
      "\n",
      "Train Epoch: 18 [0/336 (0%)]\tLoss: 0.137796\n",
      "Train Epoch: 18\tAverage Loss: 0.111929\tAccuracy: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 18/150 [01:12<09:16,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7329, Accuracy: 77/96 (80%)\n",
      "\n",
      "Train Epoch: 19 [0/336 (0%)]\tLoss: 0.113412\n",
      "Train Epoch: 19\tAverage Loss: 0.104124\tAccuracy: 98.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 19/150 [01:16<09:02,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7551, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 20 [0/336 (0%)]\tLoss: 0.063392\n",
      "Train Epoch: 20\tAverage Loss: 0.092134\tAccuracy: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/150 [01:20<09:08,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7472, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 21 [0/336 (0%)]\tLoss: 0.116526\n",
      "Train Epoch: 21\tAverage Loss: 0.096422\tAccuracy: 98.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [01:24<08:40,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7535, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 22 [0/336 (0%)]\tLoss: 0.063329\n",
      "Train Epoch: 22\tAverage Loss: 0.085638\tAccuracy: 99.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 22/150 [01:28<08:23,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7782, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 23 [0/336 (0%)]\tLoss: 0.066321\n",
      "Train Epoch: 23\tAverage Loss: 0.079789\tAccuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [01:31<08:13,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7549, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 24 [0/336 (0%)]\tLoss: 0.101929\n",
      "Train Epoch: 24\tAverage Loss: 0.083907\tAccuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 24/150 [01:35<08:06,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7636, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 25 [0/336 (0%)]\tLoss: 0.106244\n",
      "Train Epoch: 25\tAverage Loss: 0.081044\tAccuracy: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/150 [01:39<07:59,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7829, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 26 [0/336 (0%)]\tLoss: 0.065454\n",
      "Train Epoch: 26\tAverage Loss: 0.068208\tAccuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 26/150 [01:43<08:07,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7728, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 27 [0/336 (0%)]\tLoss: 0.065398\n",
      "Train Epoch: 27\tAverage Loss: 0.065510\tAccuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/150 [01:49<09:21,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7695, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 28 [0/336 (0%)]\tLoss: 0.065031\n",
      "Train Epoch: 28\tAverage Loss: 0.069303\tAccuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 28/150 [01:54<09:18,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7734, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 29 [0/336 (0%)]\tLoss: 0.055739\n",
      "Train Epoch: 29\tAverage Loss: 0.059954\tAccuracy: 99.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 29/150 [01:58<08:56,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7798, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 30 [0/336 (0%)]\tLoss: 0.074495\n",
      "Train Epoch: 30\tAverage Loss: 0.059726\tAccuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 30/150 [02:02<08:55,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7849, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 31 [0/336 (0%)]\tLoss: 0.068780\n",
      "Train Epoch: 31\tAverage Loss: 0.060365\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 31/150 [02:07<08:52,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7868, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 32 [0/336 (0%)]\tLoss: 0.059496\n",
      "Train Epoch: 32\tAverage Loss: 0.059754\tAccuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 32/150 [02:12<08:56,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7860, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 33 [0/336 (0%)]\tLoss: 0.055637\n",
      "Train Epoch: 33\tAverage Loss: 0.063720\tAccuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 33/150 [02:16<09:02,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7865, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 34 [0/336 (0%)]\tLoss: 0.053213\n",
      "Train Epoch: 34\tAverage Loss: 0.058217\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 34/150 [02:21<09:09,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7886, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 35 [0/336 (0%)]\tLoss: 0.065351\n",
      "Train Epoch: 35\tAverage Loss: 0.057886\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 35/150 [02:26<09:10,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7910, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 36 [0/336 (0%)]\tLoss: 0.044932\n",
      "Train Epoch: 36\tAverage Loss: 0.053393\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 36/150 [02:31<09:01,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7921, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 37 [0/336 (0%)]\tLoss: 0.057157\n",
      "Train Epoch: 37\tAverage Loss: 0.056749\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 37/150 [02:36<09:07,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7933, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 38 [0/336 (0%)]\tLoss: 0.053165\n",
      "Train Epoch: 38\tAverage Loss: 0.058567\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 38/150 [02:41<09:01,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7953, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 39 [0/336 (0%)]\tLoss: 0.067429\n",
      "Train Epoch: 39\tAverage Loss: 0.052140\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 39/150 [02:46<08:59,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7965, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 40 [0/336 (0%)]\tLoss: 0.057920\n",
      "Train Epoch: 40\tAverage Loss: 0.057881\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 40/150 [02:51<08:52,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7970, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 41 [0/336 (0%)]\tLoss: 0.058064\n",
      "Train Epoch: 41\tAverage Loss: 0.055945\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [02:55<08:50,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7977, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 42 [0/336 (0%)]\tLoss: 0.044478\n",
      "Train Epoch: 42\tAverage Loss: 0.056440\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 42/150 [03:00<08:43,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7984, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 43 [0/336 (0%)]\tLoss: 0.082103\n",
      "Train Epoch: 43\tAverage Loss: 0.051560\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 43/150 [03:05<08:37,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7990, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 44 [0/336 (0%)]\tLoss: 0.051248\n",
      "Train Epoch: 44\tAverage Loss: 0.058339\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 44/150 [03:10<08:37,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7998, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 45 [0/336 (0%)]\tLoss: 0.054519\n",
      "Train Epoch: 45\tAverage Loss: 0.051869\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 45/150 [03:15<08:25,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7999, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 46 [0/336 (0%)]\tLoss: 0.054373\n",
      "Train Epoch: 46\tAverage Loss: 0.053461\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 46/150 [03:20<08:20,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8002, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 47 [0/336 (0%)]\tLoss: 0.053930\n",
      "Train Epoch: 47\tAverage Loss: 0.055953\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 47/150 [03:24<08:19,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8004, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 48 [0/336 (0%)]\tLoss: 0.048269\n",
      "Train Epoch: 48\tAverage Loss: 0.056236\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 48/150 [03:29<08:09,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8007, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 49 [0/336 (0%)]\tLoss: 0.065360\n",
      "Train Epoch: 49\tAverage Loss: 0.051869\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 49/150 [03:34<08:12,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8007, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 50 [0/336 (0%)]\tLoss: 0.056818\n",
      "Train Epoch: 50\tAverage Loss: 0.050601\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 50/150 [03:39<08:13,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8008, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 51 [0/336 (0%)]\tLoss: 0.044328\n",
      "Train Epoch: 51\tAverage Loss: 0.055339\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [03:44<08:09,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8008, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 52 [0/336 (0%)]\tLoss: 0.050670\n",
      "Train Epoch: 52\tAverage Loss: 0.053572\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 52/150 [03:49<07:59,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8010, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 53 [0/336 (0%)]\tLoss: 0.043625\n",
      "Train Epoch: 53\tAverage Loss: 0.057077\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 53/150 [03:54<07:49,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8011, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 54 [0/336 (0%)]\tLoss: 0.035989\n",
      "Train Epoch: 54\tAverage Loss: 0.051028\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 54/150 [03:59<07:47,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8012, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 55 [0/336 (0%)]\tLoss: 0.068801\n",
      "Train Epoch: 55\tAverage Loss: 0.055868\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 55/150 [04:04<07:43,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8014, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 56 [0/336 (0%)]\tLoss: 0.049139\n",
      "Train Epoch: 56\tAverage Loss: 0.054420\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 56/150 [04:08<07:36,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8014, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 57 [0/336 (0%)]\tLoss: 0.046372\n",
      "Train Epoch: 57\tAverage Loss: 0.052410\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 57/150 [04:13<07:27,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8014, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 58 [0/336 (0%)]\tLoss: 0.068783\n",
      "Train Epoch: 58\tAverage Loss: 0.049814\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 58/150 [04:18<07:28,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8015, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 59 [0/336 (0%)]\tLoss: 0.044595\n",
      "Train Epoch: 59\tAverage Loss: 0.051945\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 59/150 [04:23<07:22,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8016, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 60 [0/336 (0%)]\tLoss: 0.043177\n",
      "Train Epoch: 60\tAverage Loss: 0.063015\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 60/150 [04:28<07:16,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8017, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 61 [0/336 (0%)]\tLoss: 0.054818\n",
      "Train Epoch: 61\tAverage Loss: 0.051509\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 61/150 [04:33<07:13,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8018, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 62 [0/336 (0%)]\tLoss: 0.067708\n",
      "Train Epoch: 62\tAverage Loss: 0.051321\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 62/150 [04:38<07:13,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8018, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 63 [0/336 (0%)]\tLoss: 0.043015\n",
      "Train Epoch: 63\tAverage Loss: 0.052461\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 63/150 [04:43<07:09,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8019, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 64 [0/336 (0%)]\tLoss: 0.032272\n",
      "Train Epoch: 64\tAverage Loss: 0.050057\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 64/150 [04:47<06:56,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8020, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 65 [0/336 (0%)]\tLoss: 0.065691\n",
      "Train Epoch: 65\tAverage Loss: 0.054335\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 65/150 [04:52<06:45,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8020, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 66 [0/336 (0%)]\tLoss: 0.034885\n",
      "Train Epoch: 66\tAverage Loss: 0.058161\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 66/150 [04:57<06:38,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8021, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 67 [0/336 (0%)]\tLoss: 0.064931\n",
      "Train Epoch: 67\tAverage Loss: 0.054282\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 67/150 [05:02<06:40,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8021, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 68 [0/336 (0%)]\tLoss: 0.069255\n",
      "Train Epoch: 68\tAverage Loss: 0.050375\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 68/150 [05:06<06:31,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8021, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 69 [0/336 (0%)]\tLoss: 0.064045\n",
      "Train Epoch: 69\tAverage Loss: 0.050758\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 69/150 [05:11<06:24,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8021, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 70 [0/336 (0%)]\tLoss: 0.052604\n",
      "Train Epoch: 70\tAverage Loss: 0.050169\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 70/150 [05:16<06:15,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 71 [0/336 (0%)]\tLoss: 0.058316\n",
      "Train Epoch: 71\tAverage Loss: 0.053580\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 71/150 [05:20<06:11,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 72 [0/336 (0%)]\tLoss: 0.041828\n",
      "Train Epoch: 72\tAverage Loss: 0.049934\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 72/150 [05:25<06:04,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 73 [0/336 (0%)]\tLoss: 0.058738\n",
      "Train Epoch: 73\tAverage Loss: 0.051201\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 73/150 [05:30<06:08,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 74 [0/336 (0%)]\tLoss: 0.048654\n",
      "Train Epoch: 74\tAverage Loss: 0.054032\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 74/150 [05:34<05:56,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 75 [0/336 (0%)]\tLoss: 0.066189\n",
      "Train Epoch: 75\tAverage Loss: 0.049692\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 75/150 [05:39<05:55,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8022, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 76 [0/336 (0%)]\tLoss: 0.061904\n",
      "Train Epoch: 76\tAverage Loss: 0.048790\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 76/150 [05:44<05:48,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 77 [0/336 (0%)]\tLoss: 0.081038\n",
      "Train Epoch: 77\tAverage Loss: 0.048754\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 77/150 [05:49<05:42,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 78 [0/336 (0%)]\tLoss: 0.052005\n",
      "Train Epoch: 78\tAverage Loss: 0.054557\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 78/150 [05:53<05:35,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 79 [0/336 (0%)]\tLoss: 0.065956\n",
      "Train Epoch: 79\tAverage Loss: 0.049672\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 79/150 [05:58<05:35,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 80 [0/336 (0%)]\tLoss: 0.043726\n",
      "Train Epoch: 80\tAverage Loss: 0.054293\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 80/150 [06:03<05:33,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 81 [0/336 (0%)]\tLoss: 0.056045\n",
      "Train Epoch: 81\tAverage Loss: 0.055703\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [06:08<05:28,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 82 [0/336 (0%)]\tLoss: 0.048927\n",
      "Train Epoch: 82\tAverage Loss: 0.047886\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 82/150 [06:12<05:17,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 83 [0/336 (0%)]\tLoss: 0.049236\n",
      "Train Epoch: 83\tAverage Loss: 0.061209\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 83/150 [06:16<04:55,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 84 [0/336 (0%)]\tLoss: 0.047571\n",
      "Train Epoch: 84\tAverage Loss: 0.052503\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 84/150 [06:20<04:42,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 85 [0/336 (0%)]\tLoss: 0.042316\n",
      "Train Epoch: 85\tAverage Loss: 0.054843\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 85/150 [06:24<04:31,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 86 [0/336 (0%)]\tLoss: 0.066421\n",
      "Train Epoch: 86\tAverage Loss: 0.054116\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 86/150 [06:28<04:31,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 87 [0/336 (0%)]\tLoss: 0.057561\n",
      "Train Epoch: 87\tAverage Loss: 0.051483\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 87/150 [06:32<04:22,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 88 [0/336 (0%)]\tLoss: 0.045477\n",
      "Train Epoch: 88\tAverage Loss: 0.054755\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 88/150 [06:36<04:11,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 89 [0/336 (0%)]\tLoss: 0.034342\n",
      "Train Epoch: 89\tAverage Loss: 0.059162\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 89/150 [06:40<04:06,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 90 [0/336 (0%)]\tLoss: 0.044423\n",
      "Train Epoch: 90\tAverage Loss: 0.052750\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 90/150 [06:44<04:09,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 91 [0/336 (0%)]\tLoss: 0.053988\n",
      "Train Epoch: 91\tAverage Loss: 0.054546\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 91/150 [06:50<04:30,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 92 [0/336 (0%)]\tLoss: 0.064836\n",
      "Train Epoch: 92\tAverage Loss: 0.051591\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 92/150 [06:56<04:51,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 93 [0/336 (0%)]\tLoss: 0.050407\n",
      "Train Epoch: 93\tAverage Loss: 0.051936\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 93/150 [07:02<04:54,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 94 [0/336 (0%)]\tLoss: 0.046054\n",
      "Train Epoch: 94\tAverage Loss: 0.051233\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 94/150 [07:05<04:25,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 95 [0/336 (0%)]\tLoss: 0.049022\n",
      "Train Epoch: 95\tAverage Loss: 0.056751\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 95/150 [07:09<04:10,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 96 [0/336 (0%)]\tLoss: 0.048156\n",
      "Train Epoch: 96\tAverage Loss: 0.053565\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 96/150 [07:13<03:53,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 97 [0/336 (0%)]\tLoss: 0.045238\n",
      "Train Epoch: 97\tAverage Loss: 0.057920\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 97/150 [07:17<03:42,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 98 [0/336 (0%)]\tLoss: 0.053283\n",
      "Train Epoch: 98\tAverage Loss: 0.049912\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 98/150 [07:21<03:33,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 99 [0/336 (0%)]\tLoss: 0.044348\n",
      "Train Epoch: 99\tAverage Loss: 0.053789\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 99/150 [07:25<03:31,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 100 [0/336 (0%)]\tLoss: 0.079535\n",
      "Train Epoch: 100\tAverage Loss: 0.053807\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 100/150 [07:29<03:23,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 101 [0/336 (0%)]\tLoss: 0.054667\n",
      "Train Epoch: 101\tAverage Loss: 0.052685\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [07:33<03:19,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 102 [0/336 (0%)]\tLoss: 0.072702\n",
      "Train Epoch: 102\tAverage Loss: 0.049983\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 102/150 [07:37<03:17,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 103 [0/336 (0%)]\tLoss: 0.046339\n",
      "Train Epoch: 103\tAverage Loss: 0.048417\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 103/150 [07:42<03:17,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 104 [0/336 (0%)]\tLoss: 0.062177\n",
      "Train Epoch: 104\tAverage Loss: 0.049143\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 104/150 [07:46<03:15,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 105 [0/336 (0%)]\tLoss: 0.052004\n",
      "Train Epoch: 105\tAverage Loss: 0.051991\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 105/150 [07:50<03:07,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 106 [0/336 (0%)]\tLoss: 0.079809\n",
      "Train Epoch: 106\tAverage Loss: 0.052406\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 106/150 [07:54<02:59,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 107 [0/336 (0%)]\tLoss: 0.080838\n",
      "Train Epoch: 107\tAverage Loss: 0.050911\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 107/150 [07:58<02:55,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 108 [0/336 (0%)]\tLoss: 0.060939\n",
      "Train Epoch: 108\tAverage Loss: 0.049018\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 108/150 [08:02<02:48,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 109 [0/336 (0%)]\tLoss: 0.059576\n",
      "Train Epoch: 109\tAverage Loss: 0.055646\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 109/150 [08:06<02:41,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 110 [0/336 (0%)]\tLoss: 0.042338\n",
      "Train Epoch: 110\tAverage Loss: 0.051037\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 110/150 [08:09<02:35,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 111 [0/336 (0%)]\tLoss: 0.073347\n",
      "Train Epoch: 111\tAverage Loss: 0.050222\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [08:14<02:35,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 112 [0/336 (0%)]\tLoss: 0.043888\n",
      "Train Epoch: 112\tAverage Loss: 0.055426\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 112/150 [08:18<02:35,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 113 [0/336 (0%)]\tLoss: 0.063261\n",
      "Train Epoch: 113\tAverage Loss: 0.050688\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 113/150 [08:22<02:32,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 114 [0/336 (0%)]\tLoss: 0.058120\n",
      "Train Epoch: 114\tAverage Loss: 0.050737\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 114/150 [08:27<02:30,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 115 [0/336 (0%)]\tLoss: 0.055928\n",
      "Train Epoch: 115\tAverage Loss: 0.052288\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 115/150 [08:31<02:32,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 116 [0/336 (0%)]\tLoss: 0.049100\n",
      "Train Epoch: 116\tAverage Loss: 0.048956\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 116/150 [08:35<02:24,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 117 [0/336 (0%)]\tLoss: 0.071595\n",
      "Train Epoch: 117\tAverage Loss: 0.050357\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 117/150 [08:39<02:19,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 118 [0/336 (0%)]\tLoss: 0.054503\n",
      "Train Epoch: 118\tAverage Loss: 0.052208\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 118/150 [08:44<02:16,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 119 [0/336 (0%)]\tLoss: 0.052382\n",
      "Train Epoch: 119\tAverage Loss: 0.053708\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 119/150 [08:48<02:08,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 120 [0/336 (0%)]\tLoss: 0.043349\n",
      "Train Epoch: 120\tAverage Loss: 0.052022\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 120/150 [08:52<02:02,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 121 [0/336 (0%)]\tLoss: 0.030407\n",
      "Train Epoch: 121\tAverage Loss: 0.052260\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 121/150 [08:56<01:59,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 122 [0/336 (0%)]\tLoss: 0.061308\n",
      "Train Epoch: 122\tAverage Loss: 0.049606\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 122/150 [09:01<01:59,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 123 [0/336 (0%)]\tLoss: 0.045277\n",
      "Train Epoch: 123\tAverage Loss: 0.056549\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 123/150 [09:05<01:55,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 124 [0/336 (0%)]\tLoss: 0.062437\n",
      "Train Epoch: 124\tAverage Loss: 0.058585\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 124/150 [09:09<01:50,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 125 [0/336 (0%)]\tLoss: 0.055362\n",
      "Train Epoch: 125\tAverage Loss: 0.049734\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 125/150 [09:13<01:47,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 126 [0/336 (0%)]\tLoss: 0.049470\n",
      "Train Epoch: 126\tAverage Loss: 0.051214\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 126/150 [09:18<01:44,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 127 [0/336 (0%)]\tLoss: 0.046916\n",
      "Train Epoch: 127\tAverage Loss: 0.049546\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 127/150 [09:22<01:40,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 128 [0/336 (0%)]\tLoss: 0.066133\n",
      "Train Epoch: 128\tAverage Loss: 0.051445\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 128/150 [09:27<01:38,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 129 [0/336 (0%)]\tLoss: 0.067151\n",
      "Train Epoch: 129\tAverage Loss: 0.055239\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 129/150 [09:31<01:30,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 130 [0/336 (0%)]\tLoss: 0.065426\n",
      "Train Epoch: 130\tAverage Loss: 0.050258\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 130/150 [09:35<01:23,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 131 [0/336 (0%)]\tLoss: 0.076480\n",
      "Train Epoch: 131\tAverage Loss: 0.049631\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [09:39<01:20,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 132 [0/336 (0%)]\tLoss: 0.067752\n",
      "Train Epoch: 132\tAverage Loss: 0.055605\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 132/150 [09:43<01:16,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 133 [0/336 (0%)]\tLoss: 0.048282\n",
      "Train Epoch: 133\tAverage Loss: 0.056000\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 133/150 [09:48<01:12,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 134 [0/336 (0%)]\tLoss: 0.067529\n",
      "Train Epoch: 134\tAverage Loss: 0.052834\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 134/150 [09:52<01:09,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 135 [0/336 (0%)]\tLoss: 0.056603\n",
      "Train Epoch: 135\tAverage Loss: 0.053444\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 135/150 [09:57<01:06,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 136 [0/336 (0%)]\tLoss: 0.054868\n",
      "Train Epoch: 136\tAverage Loss: 0.053761\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 136/150 [10:01<01:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 137 [0/336 (0%)]\tLoss: 0.060009\n",
      "Train Epoch: 137\tAverage Loss: 0.050561\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 137/150 [10:05<00:56,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 138 [0/336 (0%)]\tLoss: 0.039604\n",
      "Train Epoch: 138\tAverage Loss: 0.057238\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 138/150 [10:10<00:52,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 139 [0/336 (0%)]\tLoss: 0.054147\n",
      "Train Epoch: 139\tAverage Loss: 0.052673\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 139/150 [10:14<00:48,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 140 [0/336 (0%)]\tLoss: 0.059599\n",
      "Train Epoch: 140\tAverage Loss: 0.056502\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 140/150 [10:19<00:43,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 141 [0/336 (0%)]\tLoss: 0.046274\n",
      "Train Epoch: 141\tAverage Loss: 0.053148\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [10:23<00:38,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 142 [0/336 (0%)]\tLoss: 0.050175\n",
      "Train Epoch: 142\tAverage Loss: 0.050509\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 142/150 [10:27<00:34,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 143 [0/336 (0%)]\tLoss: 0.050664\n",
      "Train Epoch: 143\tAverage Loss: 0.050708\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 143/150 [10:31<00:29,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 144 [0/336 (0%)]\tLoss: 0.054876\n",
      "Train Epoch: 144\tAverage Loss: 0.054044\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 144/150 [10:36<00:25,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 145 [0/336 (0%)]\tLoss: 0.061374\n",
      "Train Epoch: 145\tAverage Loss: 0.054870\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 145/150 [10:40<00:21,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 146 [0/336 (0%)]\tLoss: 0.064989\n",
      "Train Epoch: 146\tAverage Loss: 0.051243\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 146/150 [10:45<00:17,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 147 [0/336 (0%)]\tLoss: 0.067254\n",
      "Train Epoch: 147\tAverage Loss: 0.050502\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 147/150 [10:50<00:13,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 148 [0/336 (0%)]\tLoss: 0.063089\n",
      "Train Epoch: 148\tAverage Loss: 0.050249\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 148/150 [10:54<00:09,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 149 [0/336 (0%)]\tLoss: 0.072655\n",
      "Train Epoch: 149\tAverage Loss: 0.052845\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 149/150 [10:58<00:04,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 150 [0/336 (0%)]\tLoss: 0.050512\n",
      "Train Epoch: 150\tAverage Loss: 0.054352\tAccuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:03<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8023, Accuracy: 78/96 (81%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, set_number):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.set_number = set_number\n",
    "        self.filtered_indices = self.filter()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def filter(self):\n",
    "        filtered_indices = []\n",
    "        for idx in range(len(self.data)):\n",
    "            set_value = int(self.data.iloc[idx, 1])\n",
    "            if set_value == self.set_number:\n",
    "                filtered_indices.append(idx)\n",
    "        return filtered_indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.filtered_indices[idx]\n",
    "        file = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        class_label = int(self.data.iloc[idx, 2])\n",
    "        waveform, _ = torchaudio.load(file)\n",
    "        # Normalize the waveform\n",
    "        waveform = (waveform - waveform.mean()) / waveform.std()\n",
    "        # if waveform.shape[0] != num_input_channels:\n",
    "        #     waveform = waveform.repeat(num_input_channels // waveform.shape[0], 1)\n",
    "        return waveform, class_label\n",
    "\n",
    "csv_file = 'dataset.csv'\n",
    "root_dir = 'Inregistrari'\n",
    "num_input_channels = 128  # Ensure this matches the expected input channels for the model\n",
    "\n",
    "train_dataset = My_Dataset(csv_file, root_dir, 0)\n",
    "test_dataset = My_Dataset(csv_file, root_dir, 1)\n",
    "valid_dataset = My_Dataset(csv_file, root_dir, 2)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplifiedWaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels=1, num_layers=4, num_filters=8, dilation_rates=None):\n",
    "        super(SimplifiedWaveNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.init_conv = nn.Conv1d(num_channels, num_filters, kernel_size=1)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_filters, num_filters * 2, kernel_size=3, padding=1, dilation=2)\n",
    "        self.conv2 = nn.Conv1d(num_filters * 2, num_filters * 4, kernel_size=3, padding=2, dilation=4)\n",
    "        self.conv3 = nn.Conv1d(num_filters * 4, num_filters * 8, kernel_size=3, padding=4, dilation=8)\n",
    "        self.conv4 = nn.Conv1d(num_filters * 8, num_filters * 16, kernel_size=3, padding=8, dilation=16)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(4)\n",
    "\n",
    "        self.final_conv = nn.Conv1d(256, 128, kernel_size=1)\n",
    "        self.linear = nn.Linear(128 * 57 * 1, 256)\n",
    "        self.linear2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x1)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x2)))\n",
    "        x4 = self.pool(F.relu(self.conv4(x3)))\n",
    "        x5 = self.final_conv(x4)\n",
    "        # print(x4.shape)\n",
    "        x5 = x5.view(x5.size(0), -1)\n",
    "        x6 = F.relu(self.linear(x5))\n",
    "        x7 = self.linear2(x6)\n",
    "        return x7\n",
    "\n",
    "\n",
    "\n",
    "def get_simplified_wavenet(num_classes, num_channels=1, num_layers=3, num_filters=16, dilation_rates=None, device='cpu'):\n",
    "    model = SimplifiedWaveNet(num_classes, num_channels, num_layers, num_filters, dilation_rates)\n",
    "    return model.to(device)\n",
    "\n",
    "model=get_simplified_wavenet(6)\n",
    "\n",
    "\n",
    "\n",
    "#print the number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "nr = count_parameters(model)\n",
    "print(f'The model has {nr:,} trainable parameters')\n",
    "num_input_channels = 128  # Adju\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Increased learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, scheduler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # data = data.squeeze(1)  # Remove channel dimension\n",
    "\n",
    "        # print(data.shape, target.shape)\n",
    "\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    scheduler.step()\n",
    "    print(f'Train Epoch: {epoch}\\tAverage Loss: {avg_loss:.6f}\\tAccuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "n_epoch = 150\n",
    "log_interval = 20\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval, scheduler)\n",
    "        test(model, device, test_loader)\n",
    "        torch.save(model.state_dict(), 'wavenet_command.pt')\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       start       0.75      0.88      0.81      1800\n",
      "        stop       0.70      0.61      0.65      3300\n",
      "        home       0.71      0.71      0.71      2250\n",
      "     pick_up       0.86      0.76      0.81      2850\n",
      "    approach       0.79      0.99      0.88      2100\n",
      "        free       0.94      0.89      0.92      2100\n",
      "\n",
      "    accuracy                           0.79     14400\n",
      "   macro avg       0.79      0.81      0.79     14400\n",
      "weighted avg       0.79      0.79      0.78     14400\n",
      "\n",
      "[[1584  148    7   37    7   17]\n",
      " [ 307 2007  469  309  182   26]\n",
      " [ 163  430 1598    6   16   37]\n",
      " [  33  293   10 2173  314   27]\n",
      " [   6    2    9    0 2070   13]\n",
      " [  19    4  163    0   37 1877]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming the testing loop code here\n",
    "\n",
    "# After the testing loop\n",
    "report = classification_report(all_targets, all_preds, target_names=['start', 'stop', 'home', 'pick_up', 'approach', 'free'])  # Adjust target_names based on your dataset\n",
    "print(report)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confision_matrix = confusion_matrix(all_targets, all_preds)\n",
    "print(confision_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplifiedWaveNet(\n",
      "  (init_conv): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
      "  (conv1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), dilation=(2,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(4,))\n",
      "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(8,))\n",
      "  (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(16,))\n",
      "  (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "  (linear): Linear(in_features=7296, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimplifiedWaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels=1, num_layers=4, num_filters=8, dilation_rates=None):\n",
    "        super(SimplifiedWaveNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.init_conv = nn.Conv1d(num_channels, num_filters, kernel_size=1)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_filters, num_filters * 2, kernel_size=3, padding=1, dilation=2)\n",
    "        self.conv2 = nn.Conv1d(num_filters * 2, num_filters * 4, kernel_size=3, padding=2, dilation=4)\n",
    "        self.conv3 = nn.Conv1d(num_filters * 4, num_filters * 8, kernel_size=3, padding=4, dilation=8)\n",
    "        self.conv4 = nn.Conv1d(num_filters * 8, num_filters * 16, kernel_size=3, padding=8, dilation=16)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(4)\n",
    "\n",
    "        self.final_conv = nn.Conv1d(256, 128, kernel_size=1)\n",
    "        self.linear = nn.Linear(128 * 57 * 1, 256)\n",
    "        self.linear2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x1)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x2)))\n",
    "        x4 = self.pool(F.relu(self.conv4(x3)))\n",
    "        x5 = self.final_conv(x4)\n",
    "        # print(x4.shape)\n",
    "        x5 = x5.view(x5.size(0), -1)\n",
    "        x6 = F.relu(self.linear(x5))\n",
    "        x7 = self.linear2(x6)\n",
    "        return x7\n",
    "\n",
    "\n",
    "\n",
    "def get_simplified_wavenet(num_classes, num_channels=1, num_layers=3, num_filters=16, dilation_rates=None, device='cpu'):\n",
    "    model = SimplifiedWaveNet(num_classes, num_channels, num_layers, num_filters, dilation_rates)\n",
    "    return model.to(device)\n",
    "\n",
    "model=get_simplified_wavenet(6)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 138 [0/336 (0%)]\tLoss: 0.237979\n",
      "Train Epoch: 138\tAverage Loss: 0.178298\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 138/150 [10:27<00:52,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 139 [0/336 (0%)]\tLoss: 0.171575\n",
      "Train Epoch: 139\tAverage Loss: 0.180616\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 139/150 [10:31<00:49,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 140 [0/336 (0%)]\tLoss: 0.168538\n",
      "Train Epoch: 140\tAverage Loss: 0.171533\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 140/150 [10:36<00:45,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 141 [0/336 (0%)]\tLoss: 0.200474\n",
      "Train Epoch: 141\tAverage Loss: 0.172438\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [10:41<00:41,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 142 [0/336 (0%)]\tLoss: 0.242362\n",
      "Train Epoch: 142\tAverage Loss: 0.188591\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 142/150 [10:46<00:38,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 143 [0/336 (0%)]\tLoss: 0.174322\n",
      "Train Epoch: 143\tAverage Loss: 0.181565\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 143/150 [10:52<00:35,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 144 [0/336 (0%)]\tLoss: 0.177297\n",
      "Train Epoch: 144\tAverage Loss: 0.184224\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 144/150 [10:57<00:29,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 145 [0/336 (0%)]\tLoss: 0.167013\n",
      "Train Epoch: 145\tAverage Loss: 0.185636\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 145/150 [11:02<00:25,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 146 [0/336 (0%)]\tLoss: 0.218321\n",
      "Train Epoch: 146\tAverage Loss: 0.177817\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 146/150 [11:07<00:20,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 147 [0/336 (0%)]\tLoss: 0.182773\n",
      "Train Epoch: 147\tAverage Loss: 0.189002\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 147/150 [11:12<00:15,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 148 [0/336 (0%)]\tLoss: 0.206035\n",
      "Train Epoch: 148\tAverage Loss: 0.166547\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 148/150 [11:17<00:10,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 149 [0/336 (0%)]\tLoss: 0.163532\n",
      "Train Epoch: 149\tAverage Loss: 0.172698\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 149/150 [11:22<00:05,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n",
      "Train Epoch: 150 [0/336 (0%)]\tLoss: 0.130939\n",
      "Train Epoch: 150\tAverage Loss: 0.202732\tAccuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:26<00:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9582, Accuracy: 75/96 (78%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, set_number):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.set_number = set_number\n",
    "        self.filtered_indices = self.filter()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def filter(self):\n",
    "        filtered_indices = []\n",
    "        for idx in range(len(self.data)):\n",
    "            set_value = int(self.data.iloc[idx, 1])\n",
    "            if set_value == self.set_number:\n",
    "                filtered_indices.append(idx)\n",
    "        return filtered_indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.filtered_indices[idx]\n",
    "        file = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        # class_label = int(self.data.iloc[idx, 2])\n",
    "        speaker_id = int(self.data.iloc[idx, 3])\n",
    "        waveform, _ = torchaudio.load(file)\n",
    "        # Normalize the waveform\n",
    "        waveform = (waveform - waveform.mean()) / waveform.std()\n",
    "        # if waveform.shape[0] != num_input_channels:\n",
    "        #     waveform = waveform.repeat(num_input_channels // waveform.shape[0], 1)\n",
    "        return waveform, speaker_id\n",
    "\n",
    "csv_file = 'dataset.csv'\n",
    "root_dir = 'Inregistrari'\n",
    "num_input_channels = 128  # Ensure this matches the expected input channels for the model\n",
    "\n",
    "train_dataset = My_Dataset(csv_file, root_dir, 0)\n",
    "test_dataset = My_Dataset(csv_file, root_dir, 1)\n",
    "valid_dataset = My_Dataset(csv_file, root_dir, 2)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplifiedWaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels=1, num_layers=4, num_filters=8, dilation_rates=None):\n",
    "        super(SimplifiedWaveNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.init_conv = nn.Conv1d(num_channels, num_filters, kernel_size=1)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_filters, num_filters * 2, kernel_size=3, padding=1, dilation=2)\n",
    "        self.conv2 = nn.Conv1d(num_filters * 2, num_filters * 4, kernel_size=3, padding=2, dilation=4)\n",
    "        self.conv3 = nn.Conv1d(num_filters * 4, num_filters * 8, kernel_size=3, padding=4, dilation=8)\n",
    "        self.conv4 = nn.Conv1d(num_filters * 8, num_filters * 16, kernel_size=3, padding=8, dilation=16)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(4)\n",
    "\n",
    "        self.final_conv = nn.Conv1d(256, 128, kernel_size=1)\n",
    "        self.linear = nn.Linear(128 * 57 * 1, 256)\n",
    "        self.linear2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x1)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x2)))\n",
    "        x4 = self.pool(F.relu(self.conv4(x3)))\n",
    "        x5 = self.final_conv(x4)\n",
    "        # print(x4.shape)\n",
    "        x5 = x5.view(x5.size(0), -1)\n",
    "        x6 = F.relu(self.linear(x5))\n",
    "        x7 = self.linear2(x6)\n",
    "        return x7\n",
    "\n",
    "\n",
    "\n",
    "def get_simplified_wavenet(num_classes, num_channels=1, num_layers=3, num_filters=16, dilation_rates=None, device='cpu'):\n",
    "    model = SimplifiedWaveNet(num_classes, num_channels, num_layers, num_filters, dilation_rates)\n",
    "    return model.to(device)\n",
    "\n",
    "model=get_simplified_wavenet(8)\n",
    "\n",
    "\n",
    "\n",
    "#print the number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "nr = count_parameters(model)\n",
    "print(f'The model has {nr:,} trainable parameters')\n",
    "num_input_channels = 128  # Adju\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Increased learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, scheduler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # data = data.squeeze(1)  # Remove channel dimension\n",
    "\n",
    "        # print(data.shape, target.shape)\n",
    "\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    scheduler.step()\n",
    "    print(f'Train Epoch: {epoch}\\tAverage Loss: {avg_loss:.6f}\\tAccuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "n_epoch = 150\n",
    "log_interval = 20\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval, scheduler)\n",
    "        test(model, device, test_loader)\n",
    "        torch.save(model.state_dict(), 'wavenet_command.pt')\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Anca       0.76      0.96      0.85      1350\n",
      "         Adi       0.85      0.87      0.86      1500\n",
      "        Bobo       0.83      0.87      0.85      1800\n",
      "      Danila       0.66      0.63      0.65      2250\n",
      "        Mada       0.75      0.72      0.73      1650\n",
      "        Toni       0.94      0.73      0.82      1950\n",
      "        Oana       0.69      0.64      0.66      1800\n",
      "        Luci       0.58      0.65      0.61      2100\n",
      "\n",
      "    accuracy                           0.74     14400\n",
      "   macro avg       0.76      0.76      0.75     14400\n",
      "weighted avg       0.75      0.74      0.74     14400\n",
      "\n",
      "[[1293    7    5   22    1   16    6    0]\n",
      " [  19 1301    0   16    0   28    0  136]\n",
      " [   6  158 1571   13   42    1    9    0]\n",
      " [  32   14    7 1428  188   14   41  526]\n",
      " [   7    1  164  150 1182    0  146    0]\n",
      " [ 176   14  127  175    0 1427    8   23]\n",
      " [  11    1    9  183  140   15 1153  288]\n",
      " [ 155   40    8  184   16   24  313 1360]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming the testing loop code here\n",
    "\n",
    "# After the testing loop\n",
    "report = classification_report(all_targets, all_preds, target_names=['Anca', 'Adi', 'Bobo', 'Danila', 'Mada', 'Toni', 'Oana', 'Luci'])  # Adjust target_names based on your dataset\n",
    "print(report)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confision_matrix = confusion_matrix(all_targets, all_preds)\n",
    "print(confision_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
