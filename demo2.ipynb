{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0282, -0.0244, -0.0236,  ...,  0.0104,  0.0114,  0.0126]]), 7)\n",
      "(tensor([[ 9.1553e-05, -2.7466e-04, -9.1553e-04,  ..., -3.9673e-04,\n",
      "         -4.8828e-04, -4.5776e-04]]), 4)\n",
      "(tensor([[-0.0032, -0.0017, -0.0019,  ...,  0.0024,  0.0081,  0.0065]]), 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, set_number):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the audio files.\n",
    "            set_number (int): Set number to filter the samples.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.set_number = set_number\n",
    "        self.filtered_indices = self.filter()\n",
    "        ## self.output = mfcc sau waveform \n",
    "        ## if slef.out = mfcc sau wave in get item \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def filter(self):\n",
    "        filtered_indices = []\n",
    "        for idx in range(len(self.data)):\n",
    "            set_value = int(self.data.iloc[idx, 1])\n",
    "            if set_value == self.set_number:\n",
    "                filtered_indices.append(idx)\n",
    "        return filtered_indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.filtered_indices[idx]\n",
    "        file = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        speaker_id = int(self.data.iloc[idx, 3])\n",
    "        waveform, _ = torchaudio.load(file)\n",
    "        return waveform, speaker_id\n",
    "\n",
    "csv_file = 'dataset.csv'\n",
    "root_dir = 'Inregistrari'\n",
    "train_dataset = My_Dataset(csv_file, root_dir, 0)\n",
    "test_dataset = My_Dataset(csv_file, root_dir, 1)\n",
    "valid_dataset = My_Dataset(csv_file, root_dir, 2)\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n",
    "print(valid_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 2\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pers = ['Adi', 'Anca', 'Bobo', 'Danila', 'Luci', 'Mada', 'Oana', 'Toni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes_pers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m M4(n_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mclasses_pers\u001b[49m))\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m model(torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16000\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classes_pers' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class M4(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=8, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        # self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        self.fc1 = nn.LazyLinear(n_output)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.squeeze(1)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = M4(n_input=1, n_output=len(classes_pers))\n",
    "model.to(device)\n",
    "model(torch.randn([64, 1, 16000]))\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = []\n",
    "train_a = []  # Initialize list to store average accuracy for each epoch\n",
    "\n",
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0  # Initialize total number of correct predictions\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "        total += data.size(0)\n",
    "\n",
    "        # Calculate number of correct predictions\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        total_correct += correct\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    train_l.append(avg_loss)\n",
    "\n",
    "    avg_accuracy = total_correct / total  # Calculate average accuracy for the epoch\n",
    "    train_a.append(avg_accuracy)  # Append average accuracy to the list\n",
    "\n",
    "    print(f\"\\nTrain Epoch: {epoch}\\tAverage Loss: {avg_loss:.6f}\\tAverage Accuracy: {avg_accuracy:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "test_l = []\n",
    "test_a = []\n",
    "#clear lists\n",
    "true_labels.clear()\n",
    "predictions.clear()\n",
    "test_l.clear()\n",
    "test_a.clear()\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0  # Initialize total loss for the epoch\n",
    "    total = 0  # Total number of samples processed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = get_likely_index(output)\n",
    "            correct += number_of_correct(pred, target)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "            # Calculate loss for the current batch and accumulate it\n",
    "            test_loss = F.nll_loss(output.squeeze(), target).item()\n",
    "            total_loss += test_loss * data.size(0)  # Multiply by batch size to get total loss for the batch\n",
    "            total += data.size(0)  # Accumulate the total number of samples\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        avg_loss = total_loss / total\n",
    "        accuracy = correct / total\n",
    "\n",
    "        # Append the calculated metrics to their respective lists\n",
    "        test_l.append(avg_loss)\n",
    "        test_a.append(accuracy)\n",
    "\n",
    "        print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{total} ({100. * accuracy:.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/336 (0%)]\tLoss: 2.267260\n",
      "\n",
      "Train Epoch: 1\tAverage Loss: 2.006303\tAverage Accuracy: 0.21\n",
      "\n",
      "\n",
      "Test Epoch: 1\tAccuracy: 9/96 (9%)\n",
      "\n",
      "Train Epoch: 2 [0/336 (0%)]\tLoss: 1.731269\n",
      "\n",
      "Train Epoch: 2\tAverage Loss: 1.647718\tAverage Accuracy: 0.53\n",
      "\n",
      "\n",
      "Test Epoch: 2\tAccuracy: 9/96 (9%)\n",
      "\n",
      "Train Epoch: 3 [0/336 (0%)]\tLoss: 1.501853\n",
      "\n",
      "Train Epoch: 3\tAverage Loss: 1.428789\tAverage Accuracy: 0.70\n",
      "\n",
      "\n",
      "Test Epoch: 3\tAccuracy: 9/96 (9%)\n",
      "\n",
      "Train Epoch: 4 [0/336 (0%)]\tLoss: 1.267653\n",
      "\n",
      "Train Epoch: 4\tAverage Loss: 1.234274\tAverage Accuracy: 0.82\n",
      "\n",
      "\n",
      "Test Epoch: 4\tAccuracy: 9/96 (9%)\n",
      "\n",
      "Train Epoch: 5 [0/336 (0%)]\tLoss: 1.080273\n",
      "\n",
      "Train Epoch: 5\tAverage Loss: 1.093690\tAverage Accuracy: 0.87\n",
      "\n",
      "\n",
      "Test Epoch: 5\tAccuracy: 14/96 (15%)\n",
      "\n",
      "Train Epoch: 6 [0/336 (0%)]\tLoss: 1.033160\n",
      "\n",
      "Train Epoch: 6\tAverage Loss: 0.946916\tAverage Accuracy: 0.92\n",
      "\n",
      "\n",
      "Test Epoch: 6\tAccuracy: 27/96 (28%)\n",
      "\n",
      "Train Epoch: 7 [0/336 (0%)]\tLoss: 0.815692\n",
      "\n",
      "Train Epoch: 7\tAverage Loss: 0.824474\tAverage Accuracy: 0.94\n",
      "\n",
      "\n",
      "Test Epoch: 7\tAccuracy: 47/96 (49%)\n",
      "\n",
      "Train Epoch: 8 [0/336 (0%)]\tLoss: 0.754483\n",
      "\n",
      "Train Epoch: 8\tAverage Loss: 0.691230\tAverage Accuracy: 0.97\n",
      "\n",
      "\n",
      "Test Epoch: 8\tAccuracy: 68/96 (71%)\n",
      "\n",
      "Train Epoch: 9 [0/336 (0%)]\tLoss: 0.602201\n",
      "\n",
      "Train Epoch: 9\tAverage Loss: 0.585338\tAverage Accuracy: 0.97\n",
      "\n",
      "\n",
      "Test Epoch: 9\tAccuracy: 81/96 (84%)\n",
      "\n",
      "Train Epoch: 10 [0/336 (0%)]\tLoss: 0.522324\n",
      "\n",
      "Train Epoch: 10\tAverage Loss: 0.504379\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 10\tAccuracy: 85/96 (89%)\n",
      "\n",
      "Train Epoch: 11 [0/336 (0%)]\tLoss: 0.456688\n",
      "\n",
      "Train Epoch: 11\tAverage Loss: 0.426466\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 11\tAccuracy: 85/96 (89%)\n",
      "\n",
      "Train Epoch: 12 [0/336 (0%)]\tLoss: 0.399673\n",
      "\n",
      "Train Epoch: 12\tAverage Loss: 0.375302\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 12\tAccuracy: 78/96 (81%)\n",
      "\n",
      "Train Epoch: 13 [0/336 (0%)]\tLoss: 0.347113\n",
      "\n",
      "Train Epoch: 13\tAverage Loss: 0.345805\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 13\tAccuracy: 87/96 (91%)\n",
      "\n",
      "Train Epoch: 14 [0/336 (0%)]\tLoss: 0.238764\n",
      "\n",
      "Train Epoch: 14\tAverage Loss: 0.276782\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 14\tAccuracy: 86/96 (90%)\n",
      "\n",
      "Train Epoch: 15 [0/336 (0%)]\tLoss: 0.272009\n",
      "\n",
      "Train Epoch: 15\tAverage Loss: 0.244526\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 15\tAccuracy: 88/96 (92%)\n",
      "\n",
      "Train Epoch: 16 [0/336 (0%)]\tLoss: 0.175814\n",
      "\n",
      "Train Epoch: 16\tAverage Loss: 0.214867\tAverage Accuracy: 0.99\n",
      "\n",
      "\n",
      "Test Epoch: 16\tAccuracy: 89/96 (93%)\n",
      "\n",
      "Train Epoch: 17 [0/336 (0%)]\tLoss: 0.184693\n",
      "\n",
      "Train Epoch: 17\tAverage Loss: 0.186120\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 17\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 18 [0/336 (0%)]\tLoss: 0.137167\n",
      "\n",
      "Train Epoch: 18\tAverage Loss: 0.152287\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 18\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 19 [0/336 (0%)]\tLoss: 0.123174\n",
      "\n",
      "Train Epoch: 19\tAverage Loss: 0.136592\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 19\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/336 (0%)]\tLoss: 0.101439\n",
      "\n",
      "Train Epoch: 20\tAverage Loss: 0.112364\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 20\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 21 [0/336 (0%)]\tLoss: 0.104863\n",
      "\n",
      "Train Epoch: 21\tAverage Loss: 0.102029\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 21\tAccuracy: 93/96 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/336 (0%)]\tLoss: 0.084057\n",
      "\n",
      "Train Epoch: 22\tAverage Loss: 0.105965\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 22\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 23 [0/336 (0%)]\tLoss: 0.093513\n",
      "\n",
      "Train Epoch: 23\tAverage Loss: 0.104767\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 23\tAccuracy: 90/96 (94%)\n",
      "\n",
      "Train Epoch: 24 [0/336 (0%)]\tLoss: 0.091628\n",
      "\n",
      "Train Epoch: 24\tAverage Loss: 0.098898\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 24\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 25 [0/336 (0%)]\tLoss: 0.086867\n",
      "\n",
      "Train Epoch: 25\tAverage Loss: 0.094480\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 25\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 26 [0/336 (0%)]\tLoss: 0.108602\n",
      "\n",
      "Train Epoch: 26\tAverage Loss: 0.094587\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 26\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 27 [0/336 (0%)]\tLoss: 0.094931\n",
      "\n",
      "Train Epoch: 27\tAverage Loss: 0.094693\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 27\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 28 [0/336 (0%)]\tLoss: 0.086517\n",
      "\n",
      "Train Epoch: 28\tAverage Loss: 0.094766\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 28\tAccuracy: 90/96 (94%)\n",
      "\n",
      "Train Epoch: 29 [0/336 (0%)]\tLoss: 0.085068\n",
      "\n",
      "Train Epoch: 29\tAverage Loss: 0.093111\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 29\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 30 [0/336 (0%)]\tLoss: 0.101340\n",
      "\n",
      "Train Epoch: 30\tAverage Loss: 0.091953\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 30\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 31 [0/336 (0%)]\tLoss: 0.098004\n",
      "\n",
      "Train Epoch: 31\tAverage Loss: 0.092869\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 31\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 32 [0/336 (0%)]\tLoss: 0.081680\n",
      "\n",
      "Train Epoch: 32\tAverage Loss: 0.086603\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 32\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 33 [0/336 (0%)]\tLoss: 0.072857\n",
      "\n",
      "Train Epoch: 33\tAverage Loss: 0.091678\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 33\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 34 [0/336 (0%)]\tLoss: 0.072004\n",
      "\n",
      "Train Epoch: 34\tAverage Loss: 0.085399\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 34\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 35 [0/336 (0%)]\tLoss: 0.099861\n",
      "\n",
      "Train Epoch: 35\tAverage Loss: 0.084609\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 35\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 36 [0/336 (0%)]\tLoss: 0.099997\n",
      "\n",
      "Train Epoch: 36\tAverage Loss: 0.082734\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 36\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 37 [0/336 (0%)]\tLoss: 0.098510\n",
      "\n",
      "Train Epoch: 37\tAverage Loss: 0.083303\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 37\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 38 [0/336 (0%)]\tLoss: 0.086091\n",
      "\n",
      "Train Epoch: 38\tAverage Loss: 0.085179\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 38\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 39 [0/336 (0%)]\tLoss: 0.093586\n",
      "\n",
      "Train Epoch: 39\tAverage Loss: 0.083468\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 39\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 40 [0/336 (0%)]\tLoss: 0.072998\n",
      "\n",
      "Train Epoch: 40\tAverage Loss: 0.078685\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 40\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 41 [0/336 (0%)]\tLoss: 0.102781\n",
      "\n",
      "Train Epoch: 41\tAverage Loss: 0.077565\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 41\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 42 [0/336 (0%)]\tLoss: 0.074768\n",
      "\n",
      "Train Epoch: 42\tAverage Loss: 0.082075\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 42\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 43 [0/336 (0%)]\tLoss: 0.066157\n",
      "\n",
      "Train Epoch: 43\tAverage Loss: 0.078500\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 43\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 44 [0/336 (0%)]\tLoss: 0.079757\n",
      "\n",
      "Train Epoch: 44\tAverage Loss: 0.085208\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 44\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 45 [0/336 (0%)]\tLoss: 0.068727\n",
      "\n",
      "Train Epoch: 45\tAverage Loss: 0.081011\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 45\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 46 [0/336 (0%)]\tLoss: 0.069990\n",
      "\n",
      "Train Epoch: 46\tAverage Loss: 0.076905\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 46\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 47 [0/336 (0%)]\tLoss: 0.080873\n",
      "\n",
      "Train Epoch: 47\tAverage Loss: 0.080420\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 47\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 48 [0/336 (0%)]\tLoss: 0.072341\n",
      "\n",
      "Train Epoch: 48\tAverage Loss: 0.076866\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 48\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 49 [0/336 (0%)]\tLoss: 0.068398\n",
      "\n",
      "Train Epoch: 49\tAverage Loss: 0.081340\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 49\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 50 [0/336 (0%)]\tLoss: 0.071431\n",
      "\n",
      "Train Epoch: 50\tAverage Loss: 0.079563\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 50\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 51 [0/336 (0%)]\tLoss: 0.077733\n",
      "\n",
      "Train Epoch: 51\tAverage Loss: 0.077144\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 51\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 52 [0/336 (0%)]\tLoss: 0.079342\n",
      "\n",
      "Train Epoch: 52\tAverage Loss: 0.085408\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 52\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 53 [0/336 (0%)]\tLoss: 0.072571\n",
      "\n",
      "Train Epoch: 53\tAverage Loss: 0.076322\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 53\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 54 [0/336 (0%)]\tLoss: 0.079277\n",
      "\n",
      "Train Epoch: 54\tAverage Loss: 0.082512\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 54\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 55 [0/336 (0%)]\tLoss: 0.070815\n",
      "\n",
      "Train Epoch: 55\tAverage Loss: 0.077086\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 55\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 56 [0/336 (0%)]\tLoss: 0.074338\n",
      "\n",
      "Train Epoch: 56\tAverage Loss: 0.076937\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 56\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 57 [0/336 (0%)]\tLoss: 0.079907\n",
      "\n",
      "Train Epoch: 57\tAverage Loss: 0.080850\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 57\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 58 [0/336 (0%)]\tLoss: 0.064206\n",
      "\n",
      "Train Epoch: 58\tAverage Loss: 0.073986\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 58\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 59 [0/336 (0%)]\tLoss: 0.069329\n",
      "\n",
      "Train Epoch: 59\tAverage Loss: 0.078151\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 59\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 60 [0/336 (0%)]\tLoss: 0.088463\n",
      "\n",
      "Train Epoch: 60\tAverage Loss: 0.076619\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 60\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 61 [0/336 (0%)]\tLoss: 0.067933\n",
      "\n",
      "Train Epoch: 61\tAverage Loss: 0.076518\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 61\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 62 [0/336 (0%)]\tLoss: 0.079073\n",
      "\n",
      "Train Epoch: 62\tAverage Loss: 0.074013\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 62\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 63 [0/336 (0%)]\tLoss: 0.068406\n",
      "\n",
      "Train Epoch: 63\tAverage Loss: 0.074631\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 63\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 64 [0/336 (0%)]\tLoss: 0.093122\n",
      "\n",
      "Train Epoch: 64\tAverage Loss: 0.076348\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 64\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 65 [0/336 (0%)]\tLoss: 0.081187\n",
      "\n",
      "Train Epoch: 65\tAverage Loss: 0.077225\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 65\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 66 [0/336 (0%)]\tLoss: 0.074631\n",
      "\n",
      "Train Epoch: 66\tAverage Loss: 0.076165\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 66\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 67 [0/336 (0%)]\tLoss: 0.077336\n",
      "\n",
      "Train Epoch: 67\tAverage Loss: 0.079413\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 67\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 68 [0/336 (0%)]\tLoss: 0.068624\n",
      "\n",
      "Train Epoch: 68\tAverage Loss: 0.078728\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 68\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 69 [0/336 (0%)]\tLoss: 0.082446\n",
      "\n",
      "Train Epoch: 69\tAverage Loss: 0.076701\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 69\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 70 [0/336 (0%)]\tLoss: 0.073551\n",
      "\n",
      "Train Epoch: 70\tAverage Loss: 0.080381\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 70\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 71 [0/336 (0%)]\tLoss: 0.065195\n",
      "\n",
      "Train Epoch: 71\tAverage Loss: 0.080946\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 71\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 72 [0/336 (0%)]\tLoss: 0.075471\n",
      "\n",
      "Train Epoch: 72\tAverage Loss: 0.076601\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 72\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 73 [0/336 (0%)]\tLoss: 0.068395\n",
      "\n",
      "Train Epoch: 73\tAverage Loss: 0.076402\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 73\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 74 [0/336 (0%)]\tLoss: 0.069525\n",
      "\n",
      "Train Epoch: 74\tAverage Loss: 0.077760\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 74\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 75 [0/336 (0%)]\tLoss: 0.084766\n",
      "\n",
      "Train Epoch: 75\tAverage Loss: 0.074721\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 75\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 76 [0/336 (0%)]\tLoss: 0.069001\n",
      "\n",
      "Train Epoch: 76\tAverage Loss: 0.078333\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 76\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 77 [0/336 (0%)]\tLoss: 0.066607\n",
      "\n",
      "Train Epoch: 77\tAverage Loss: 0.077936\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 77\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 78 [0/336 (0%)]\tLoss: 0.088521\n",
      "\n",
      "Train Epoch: 78\tAverage Loss: 0.078401\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 78\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 79 [0/336 (0%)]\tLoss: 0.086684\n",
      "\n",
      "Train Epoch: 79\tAverage Loss: 0.078628\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 79\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 80 [0/336 (0%)]\tLoss: 0.079534\n",
      "\n",
      "Train Epoch: 80\tAverage Loss: 0.080365\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 80\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 81 [0/336 (0%)]\tLoss: 0.074567\n",
      "\n",
      "Train Epoch: 81\tAverage Loss: 0.080320\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 81\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 82 [0/336 (0%)]\tLoss: 0.072819\n",
      "\n",
      "Train Epoch: 82\tAverage Loss: 0.073932\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 82\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 83 [0/336 (0%)]\tLoss: 0.065584\n",
      "\n",
      "Train Epoch: 83\tAverage Loss: 0.073999\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 83\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 84 [0/336 (0%)]\tLoss: 0.060697\n",
      "\n",
      "Train Epoch: 84\tAverage Loss: 0.074961\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 84\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 85 [0/336 (0%)]\tLoss: 0.062811\n",
      "\n",
      "Train Epoch: 85\tAverage Loss: 0.076831\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 85\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 86 [0/336 (0%)]\tLoss: 0.065371\n",
      "\n",
      "Train Epoch: 86\tAverage Loss: 0.073536\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 86\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 87 [0/336 (0%)]\tLoss: 0.069635\n",
      "\n",
      "Train Epoch: 87\tAverage Loss: 0.083344\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 87\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 88 [0/336 (0%)]\tLoss: 0.075753\n",
      "\n",
      "Train Epoch: 88\tAverage Loss: 0.076445\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 88\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 89 [0/336 (0%)]\tLoss: 0.073294\n",
      "\n",
      "Train Epoch: 89\tAverage Loss: 0.079158\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 89\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 90 [0/336 (0%)]\tLoss: 0.083423\n",
      "\n",
      "Train Epoch: 90\tAverage Loss: 0.079397\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 90\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 91 [0/336 (0%)]\tLoss: 0.059616\n",
      "\n",
      "Train Epoch: 91\tAverage Loss: 0.079716\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 91\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 92 [0/336 (0%)]\tLoss: 0.062828\n",
      "\n",
      "Train Epoch: 92\tAverage Loss: 0.075757\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 92\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 93 [0/336 (0%)]\tLoss: 0.073585\n",
      "\n",
      "Train Epoch: 93\tAverage Loss: 0.078857\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 93\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 94 [0/336 (0%)]\tLoss: 0.087074\n",
      "\n",
      "Train Epoch: 94\tAverage Loss: 0.077421\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 94\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 95 [0/336 (0%)]\tLoss: 0.069644\n",
      "\n",
      "Train Epoch: 95\tAverage Loss: 0.076777\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 95\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 96 [0/336 (0%)]\tLoss: 0.069891\n",
      "\n",
      "Train Epoch: 96\tAverage Loss: 0.075880\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 96\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 97 [0/336 (0%)]\tLoss: 0.078539\n",
      "\n",
      "Train Epoch: 97\tAverage Loss: 0.074081\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 97\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 98 [0/336 (0%)]\tLoss: 0.067181\n",
      "\n",
      "Train Epoch: 98\tAverage Loss: 0.077899\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 98\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 99 [0/336 (0%)]\tLoss: 0.068082\n",
      "\n",
      "Train Epoch: 99\tAverage Loss: 0.074221\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 99\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 100 [0/336 (0%)]\tLoss: 0.074214\n",
      "\n",
      "Train Epoch: 100\tAverage Loss: 0.076760\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 100\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 101 [0/336 (0%)]\tLoss: 0.073806\n",
      "\n",
      "Train Epoch: 101\tAverage Loss: 0.075228\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 101\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 102 [0/336 (0%)]\tLoss: 0.079110\n",
      "\n",
      "Train Epoch: 102\tAverage Loss: 0.076203\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 102\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 103 [0/336 (0%)]\tLoss: 0.064738\n",
      "\n",
      "Train Epoch: 103\tAverage Loss: 0.075279\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 103\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 104 [0/336 (0%)]\tLoss: 0.099677\n",
      "\n",
      "Train Epoch: 104\tAverage Loss: 0.079473\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 104\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 105 [0/336 (0%)]\tLoss: 0.063031\n",
      "\n",
      "Train Epoch: 105\tAverage Loss: 0.074899\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 105\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 106 [0/336 (0%)]\tLoss: 0.066983\n",
      "\n",
      "Train Epoch: 106\tAverage Loss: 0.078916\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 106\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 107 [0/336 (0%)]\tLoss: 0.086310\n",
      "\n",
      "Train Epoch: 107\tAverage Loss: 0.077365\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 107\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 108 [0/336 (0%)]\tLoss: 0.072825\n",
      "\n",
      "Train Epoch: 108\tAverage Loss: 0.074509\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 108\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 109 [0/336 (0%)]\tLoss: 0.067223\n",
      "\n",
      "Train Epoch: 109\tAverage Loss: 0.083175\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 109\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 110 [0/336 (0%)]\tLoss: 0.086443\n",
      "\n",
      "Train Epoch: 110\tAverage Loss: 0.079689\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 110\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 111 [0/336 (0%)]\tLoss: 0.073460\n",
      "\n",
      "Train Epoch: 111\tAverage Loss: 0.077337\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 111\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 112 [0/336 (0%)]\tLoss: 0.068487\n",
      "\n",
      "Train Epoch: 112\tAverage Loss: 0.077616\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 112\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 113 [0/336 (0%)]\tLoss: 0.079517\n",
      "\n",
      "Train Epoch: 113\tAverage Loss: 0.078322\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 113\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 114 [0/336 (0%)]\tLoss: 0.088821\n",
      "\n",
      "Train Epoch: 114\tAverage Loss: 0.079930\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 114\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 115 [0/336 (0%)]\tLoss: 0.071177\n",
      "\n",
      "Train Epoch: 115\tAverage Loss: 0.074180\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 115\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 116 [0/336 (0%)]\tLoss: 0.071757\n",
      "\n",
      "Train Epoch: 116\tAverage Loss: 0.074848\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 116\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 117 [0/336 (0%)]\tLoss: 0.083696\n",
      "\n",
      "Train Epoch: 117\tAverage Loss: 0.074554\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 117\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 118 [0/336 (0%)]\tLoss: 0.071291\n",
      "\n",
      "Train Epoch: 118\tAverage Loss: 0.075968\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 118\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 119 [0/336 (0%)]\tLoss: 0.064780\n",
      "\n",
      "Train Epoch: 119\tAverage Loss: 0.076532\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 119\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 120 [0/336 (0%)]\tLoss: 0.085764\n",
      "\n",
      "Train Epoch: 120\tAverage Loss: 0.076096\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 120\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 121 [0/336 (0%)]\tLoss: 0.072474\n",
      "\n",
      "Train Epoch: 121\tAverage Loss: 0.077099\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 121\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 122 [0/336 (0%)]\tLoss: 0.093152\n",
      "\n",
      "Train Epoch: 122\tAverage Loss: 0.076171\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 122\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 123 [0/336 (0%)]\tLoss: 0.075443\n",
      "\n",
      "Train Epoch: 123\tAverage Loss: 0.076978\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 123\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 124 [0/336 (0%)]\tLoss: 0.065582\n",
      "\n",
      "Train Epoch: 124\tAverage Loss: 0.078318\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 124\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 125 [0/336 (0%)]\tLoss: 0.094224\n",
      "\n",
      "Train Epoch: 125\tAverage Loss: 0.074806\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 125\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 126 [0/336 (0%)]\tLoss: 0.082941\n",
      "\n",
      "Train Epoch: 126\tAverage Loss: 0.076917\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 126\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 127 [0/336 (0%)]\tLoss: 0.072692\n",
      "\n",
      "Train Epoch: 127\tAverage Loss: 0.075792\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 127\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 128 [0/336 (0%)]\tLoss: 0.070785\n",
      "\n",
      "Train Epoch: 128\tAverage Loss: 0.080306\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 128\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 129 [0/336 (0%)]\tLoss: 0.085844\n",
      "\n",
      "Train Epoch: 129\tAverage Loss: 0.079543\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 129\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 130 [0/336 (0%)]\tLoss: 0.086759\n",
      "\n",
      "Train Epoch: 130\tAverage Loss: 0.076264\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 130\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 131 [0/336 (0%)]\tLoss: 0.064270\n",
      "\n",
      "Train Epoch: 131\tAverage Loss: 0.074380\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 131\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 132 [0/336 (0%)]\tLoss: 0.066672\n",
      "\n",
      "Train Epoch: 132\tAverage Loss: 0.076579\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 132\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 133 [0/336 (0%)]\tLoss: 0.074702\n",
      "\n",
      "Train Epoch: 133\tAverage Loss: 0.075470\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 133\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 134 [0/336 (0%)]\tLoss: 0.068637\n",
      "\n",
      "Train Epoch: 134\tAverage Loss: 0.077668\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 134\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 135 [0/336 (0%)]\tLoss: 0.084795\n",
      "\n",
      "Train Epoch: 135\tAverage Loss: 0.080280\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 135\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 136 [0/336 (0%)]\tLoss: 0.076014\n",
      "\n",
      "Train Epoch: 136\tAverage Loss: 0.077316\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 136\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 137 [0/336 (0%)]\tLoss: 0.069483\n",
      "\n",
      "Train Epoch: 137\tAverage Loss: 0.076519\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 137\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 138 [0/336 (0%)]\tLoss: 0.065836\n",
      "\n",
      "Train Epoch: 138\tAverage Loss: 0.074023\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 138\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 139 [0/336 (0%)]\tLoss: 0.068289\n",
      "\n",
      "Train Epoch: 139\tAverage Loss: 0.080940\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 139\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 140 [0/336 (0%)]\tLoss: 0.082710\n",
      "\n",
      "Train Epoch: 140\tAverage Loss: 0.080681\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 140\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 141 [0/336 (0%)]\tLoss: 0.066928\n",
      "\n",
      "Train Epoch: 141\tAverage Loss: 0.074422\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 141\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 142 [0/336 (0%)]\tLoss: 0.083730\n",
      "\n",
      "Train Epoch: 142\tAverage Loss: 0.078540\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 142\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 143 [0/336 (0%)]\tLoss: 0.064895\n",
      "\n",
      "Train Epoch: 143\tAverage Loss: 0.074806\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 143\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 144 [0/336 (0%)]\tLoss: 0.084718\n",
      "\n",
      "Train Epoch: 144\tAverage Loss: 0.076565\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 144\tAccuracy: 91/96 (95%)\n",
      "\n",
      "Train Epoch: 145 [0/336 (0%)]\tLoss: 0.068809\n",
      "\n",
      "Train Epoch: 145\tAverage Loss: 0.075270\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 145\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 146 [0/336 (0%)]\tLoss: 0.087983\n",
      "\n",
      "Train Epoch: 146\tAverage Loss: 0.079379\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 146\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 147 [0/336 (0%)]\tLoss: 0.081814\n",
      "\n",
      "Train Epoch: 147\tAverage Loss: 0.076656\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 147\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 148 [0/336 (0%)]\tLoss: 0.091883\n",
      "\n",
      "Train Epoch: 148\tAverage Loss: 0.078300\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 148\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 149 [0/336 (0%)]\tLoss: 0.073317\n",
      "\n",
      "Train Epoch: 149\tAverage Loss: 0.081724\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 149\tAccuracy: 92/96 (96%)\n",
      "\n",
      "Train Epoch: 150 [0/336 (0%)]\tLoss: 0.082802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [01:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 150\tAverage Loss: 0.082332\tAverage Accuracy: 1.00\n",
      "\n",
      "\n",
      "Test Epoch: 150\tAccuracy: 92/96 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "log_interval = 20\n",
    "n_epoch = 150\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, epoch, log_interval)\n",
    "        \n",
    "        test(model, epoch)\n",
    "        torch.save(model.state_dict(), 'best_speaker.pt')\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start recording\n",
      "Stop recording\n",
      "Adi\n"
     ]
    }
   ],
   "source": [
    "#record 10 audios of 1 second each and save them in the recordings folder\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import torch\n",
    "import torchaudio\n",
    "model = M4()\n",
    "\n",
    "freq = 16000\n",
    "duration = 1\n",
    "\n",
    "\n",
    "#load best_speaker.pt\n",
    "model.load_state_dict(torch.load('best_speaker.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Define device based on CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "classes_persons = ['Adi', 'Anca', 'Bobo', 'Danila', 'Luci', 'Mada', 'Oana', 'Toni']\n",
    "\n",
    "\n",
    "# record audio\n",
    "recording = sd.rec(int(duration * freq),\n",
    "                       samplerate=freq, channels=1)\n",
    "print(\"Start recording\")\n",
    "sd.wait()\n",
    "print(\"Stop recording\")\n",
    "write(f\"test1.wav\", freq, recording)\n",
    "\n",
    "#load the audio \n",
    "waveform, _ = torchaudio.load(\"test1.wav\")\n",
    "waveform = waveform.unsqueeze(0)  # Add a batch dimension if necessary\n",
    "\n",
    "# Ensure the waveform is on the correct device\n",
    "waveform = waveform.to(device)\n",
    "\n",
    "# Now proceed with the prediction\n",
    "output = model(waveform)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(classes_persons[predicted])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
